"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXEMPLO: FRONTEND COM STREAMING (app.py)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Este arquivo mostra como a seÃ§Ã£o de geraÃ§Ã£o do app.py ficaria com streaming

LocalizaÃ§Ã£o no arquivo original: app.py, linhas ~200-320
"""

import streamlit as st
import time

# =============================================================================
# VERSÃƒO 1: USANDO st.empty() E ATUALIZAÃ‡ÃƒO MANUAL
# =============================================================================

def gerar_com_streaming_v1():
    """
    VersÃ£o 1: Controle manual do streaming com st.empty()

    Vantagens:
    - Controle total sobre a renderizaÃ§Ã£o
    - Pode adicionar formataÃ§Ã£o customizada
    - Funciona em qualquer versÃ£o do Streamlit

    Desvantagens:
    - Mais cÃ³digo
    - Precisa gerenciar estado manualmente
    """

    # Dentro do if uploaded_file no app.py
    if st.button("ğŸš€ Gerar ContestaÃ§Ã£o", type="primary", use_container_width=True):

        # Inicializar flag de geraÃ§Ã£o
        st.session_state.gerando = True

        try:
            # =========================================
            # ETAPA 1-3: Processamento (igual ao original)
            # =========================================
            with st.spinner("ğŸ“„ Processando petiÃ§Ã£o inicial..."):
                # 1. Processar documento
                dados_peticao = st.session_state.processor.processar_documento(
                    uploaded_file
                )
                st.session_state.dados_peticao = dados_peticao

                # 2. Buscar contexto RAG
                resultado_rag = st.session_state.rag.buscar_contexto(
                    dados_peticao['fatos_completos']
                )

                # 3. Construir contexto otimizado
                contexto_rag = st.session_state.context_builder.construir_contexto(
                    dados_peticao,
                    resultado_rag
                )

            st.success("âœ… Processamento concluÃ­do!")

            # =========================================
            # ETAPA 4: GERAÃ‡ÃƒO COM STREAMING (NOVO!)
            # =========================================
            st.divider()
            st.header("ğŸ“„ GeraÃ§Ã£o da ContestaÃ§Ã£o")

            # Containers para atualizaÃ§Ã£o dinÃ¢mica
            status_container = st.empty()
            texto_container = st.empty()
            metrics_container = st.empty()

            # VariÃ¡veis de acumulaÃ§Ã£o
            texto_acumulado = ""
            metadados_finais = None
            inicio_geracao = time.time()

            # Mostrar status inicial
            with status_container.container():
                st.info("ğŸŒŠ Gerando contestaÃ§Ã£o em tempo real...")

            # Obter generator de streaming
            stream_generator = st.session_state.llm_generator.gerar_contestacao(
                dados_peticao=dados_peticao,
                contexto_rag=contexto_rag,
                temperatura=temperatura,  # Do sidebar
                top_k=top_k,              # Do sidebar
                max_tokens=max_tokens,    # Do sidebar
                stream=True  # ğŸ”¥ ATIVAR STREAMING
            )

            # =========================================
            # PROCESSAR CHUNKS EM TEMPO REAL
            # =========================================
            for chunk_data in stream_generator:

                # Verificar erro
                if chunk_data.get('error'):
                    with status_container.container():
                        st.error(f"âŒ Erro na geraÃ§Ã£o: {chunk_data['error']}")
                    break

                # Processar chunk normal
                if not chunk_data['done']:
                    # Acumular texto
                    texto_acumulado += chunk_data['chunk']

                    # Atualizar display em tempo real
                    with texto_container.container():
                        st.markdown("### ğŸ“œ ContestaÃ§Ã£o")

                        # Usar markdown para melhor renderizaÃ§Ã£o
                        st.markdown(f"""
                        <div style="
                            background-color: #f0f2f6;
                            padding: 20px;
                            border-radius: 10px;
                            border-left: 5px solid #1f77b4;
                            font-family: 'Georgia', serif;
                            line-height: 1.8;
                            max-height: 600px;
                            overflow-y: auto;
                        ">
                        {texto_acumulado}
                        <span style="animation: blink 1s infinite;">â–Š</span>
                        </div>
                        """, unsafe_allow_html=True)

                        # CSS para animaÃ§Ã£o do cursor
                        st.markdown("""
                        <style>
                        @keyframes blink {
                            0%, 50% { opacity: 1; }
                            51%, 100% { opacity: 0; }
                        }
                        </style>
                        """, unsafe_allow_html=True)

                else:
                    # Ãšltimo chunk - salvar metadados
                    metadados_finais = chunk_data.get('metadata')

            # Tempo total
            tempo_total = time.time() - inicio_geracao

            # Atualizar status final
            with status_container.container():
                st.success(f"âœ… ContestaÃ§Ã£o gerada com sucesso em {tempo_total:.1f}s!")

            # =========================================
            # ETAPA 5: VALIDAÃ‡ÃƒO DE QUALIDADE
            # =========================================
            with st.spinner("ğŸ” Validando qualidade..."):
                validacao = st.session_state.validator.validar_contestacao(
                    texto_acumulado,
                    dados_peticao
                )

            # =========================================
            # SALVAR RESULTADO NO SESSION STATE
            # =========================================
            st.session_state.resultado = {
                'contestacao': texto_acumulado,
                'dados_peticao': dados_peticao,
                'contexto_rag': contexto_rag,
                'metadados': metadados_finais,
                'validacao': validacao,
                'custo': metadados_finais['custo_estimado']
            }

            # =========================================
            # MOSTRAR MÃ‰TRICAS FINAIS
            # =========================================
            with metrics_container.container():
                st.markdown("### ğŸ“Š MÃ©tricas")

                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric(
                        "Tipo de Caso",
                        dados_peticao.get('tipo_caso', 'N/A')
                    )

                with col2:
                    conf = dados_peticao.get('confianca', 0)
                    st.metric("ConfianÃ§a", f"{conf:.1%}")

                with col3:
                    st.metric(
                        "Tokens Gerados",
                        f"{metadados_finais['output_tokens']:,}"
                    )

                with col4:
                    st.metric(
                        "Custo",
                        f"${metadados_finais['custo_estimado']:.4f}"
                    )

                # MÃ©tricas de qualidade
                if mostrar_metricas:  # Toggle do sidebar
                    st.divider()

                    val = validacao
                    met = val['metricas']

                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric("Score Geral", f"{met['score_qualidade']}/100")

                    with col2:
                        st.metric("ClassificaÃ§Ã£o", met['classificacao'])

                    with col3:
                        st.metric("CitaÃ§Ãµes Legais", met['citacoes_legais'])

                    with col4:
                        st.metric("Completude", f"{met['completude_estrutural']:.0%}")

                    # Alertas
                    if val['alertas']:
                        st.warning("âš ï¸ **Alertas:**")
                        for alerta in val['alertas']:
                            st.warning(f"â€¢ {alerta}")

            # =========================================
            # BOTÃ•ES DE AÃ‡ÃƒO
            # =========================================
            st.divider()

            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button("ğŸ“¥ Download DOCX", use_container_width=True):
                    # ... lÃ³gica de download ...
                    pass

            with col2:
                if st.button("ğŸ“‹ Copiar Texto", use_container_width=True):
                    # ... lÃ³gica de cÃ³pia ...
                    pass

            with col3:
                if st.button("ğŸ”„ Regenerar", use_container_width=True):
                    st.session_state.resultado = None
                    st.rerun()

        except Exception as e:
            st.error(f"âŒ Erro: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

        finally:
            st.session_state.gerando = False


# =============================================================================
# VERSÃƒO 2: USANDO st.write_stream() (MAIS SIMPLES)
# =============================================================================

def gerar_com_streaming_v2():
    """
    VersÃ£o 2: Usando st.write_stream() nativo do Streamlit

    Vantagens:
    - CÃ³digo mais simples e limpo
    - Otimizado pelo Streamlit
    - Menos cÃ³digo para manter

    Desvantagens:
    - Menos controle sobre renderizaÃ§Ã£o
    - Requer Streamlit >= 1.29.0
    """

    if st.button("ğŸš€ Gerar ContestaÃ§Ã£o", type="primary", use_container_width=True):

        st.session_state.gerando = True

        try:
            # Processamento (igual v1)
            with st.spinner("ğŸ“„ Processando petiÃ§Ã£o inicial..."):
                dados_peticao = st.session_state.processor.processar_documento(uploaded_file)
                resultado_rag = st.session_state.rag.buscar_contexto(dados_peticao['fatos_completos'])
                contexto_rag = st.session_state.context_builder.construir_contexto(dados_peticao, resultado_rag)

            st.success("âœ… Processamento concluÃ­do!")
            st.divider()

            # =========================================
            # STREAMING COM st.write_stream()
            # =========================================
            st.header("ğŸ“„ GeraÃ§Ã£o da ContestaÃ§Ã£o")

            # Obter generator
            stream_generator = st.session_state.llm_generator.gerar_contestacao(
                dados_peticao=dados_peticao,
                contexto_rag=contexto_rag,
                temperatura=temperatura,
                top_k=top_k,
                max_tokens=max_tokens,
                stream=True
            )

            # FunÃ§Ã£o adapter para st.write_stream()
            def text_stream():
                """Adapter que extrai apenas o texto dos chunks"""
                for chunk_data in stream_generator:
                    if not chunk_data['done'] and not chunk_data.get('error'):
                        yield chunk_data['chunk']
                    elif chunk_data.get('error'):
                        st.error(f"âŒ Erro: {chunk_data['error']}")
                        return

            # Exibir streaming (SUPER SIMPLES!)
            st.markdown("### ğŸ“œ ContestaÃ§Ã£o")
            texto_acumulado = st.write_stream(text_stream())

            # Salvar no session state
            st.session_state.resultado = {
                'contestacao': texto_acumulado,
                'dados_peticao': dados_peticao,
                # ... resto dos dados ...
            }

            # MÃ©tricas e validaÃ§Ã£o (igual v1)
            # ...

        finally:
            st.session_state.gerando = False


# =============================================================================
# VERSÃƒO 3: STREAMING COM PROGRESS BAR
# =============================================================================

def gerar_com_streaming_v3():
    """
    VersÃ£o 3: Com barra de progresso estimada

    Vantagens:
    - Feedback visual de progresso
    - UsuÃ¡rio vÃª quanto falta
    - Mais profissional

    Desvantagens:
    - Progresso Ã© estimado (nÃ£o preciso)
    - Mais complexo
    """

    if st.button("ğŸš€ Gerar ContestaÃ§Ã£o", type="primary", use_container_width=True):

        # ... processamento inicial ...

        st.header("ğŸ“„ GeraÃ§Ã£o da ContestaÃ§Ã£o")

        # Containers
        progress_bar = st.progress(0)
        progress_text = st.empty()
        texto_container = st.empty()

        # VariÃ¡veis
        texto_acumulado = ""
        tokens_estimados = max_tokens  # Estimativa
        tokens_gerados = 0

        # Generator
        stream_generator = st.session_state.llm_generator.gerar_contestacao(
            dados_peticao=dados_peticao,
            contexto_rag=contexto_rag,
            stream=True
        )

        # Processar chunks com progresso
        for chunk_data in stream_generator:

            if not chunk_data['done']:
                # Acumular
                chunk_text = chunk_data['chunk']
                texto_acumulado += chunk_text

                # Estimar tokens (rough: ~4 chars = 1 token)
                tokens_gerados += len(chunk_text) / 4

                # Calcular progresso
                progresso = min(tokens_gerados / tokens_estimados, 0.99)

                # Atualizar barra
                progress_bar.progress(progresso)
                progress_text.text(f"Gerando... {progresso*100:.0f}%")

                # Atualizar texto
                with texto_container.container():
                    st.markdown(f"```\n{texto_acumulado}\n```")

            else:
                # ConcluÃ­do
                progress_bar.progress(1.0)
                progress_text.text("âœ… ConcluÃ­do!")

                metadados_finais = chunk_data['metadata']

        # ... resto do cÃ³digo ...


# =============================================================================
# DICAS DE IMPLEMENTAÃ‡ÃƒO
# =============================================================================

"""
RECOMENDAÃ‡ÃƒO:

Para este projeto, recomendo usar a VERSÃƒO 1 (st.empty() com controle manual)
porque:

1. Permite adicionar o cursor piscando (melhor UX)
2. Pode formatar o texto como documento legal (fonte serif, espaÃ§amento)
3. Funciona em qualquer versÃ£o do Streamlit
4. DÃ¡ controle total sobre a renderizaÃ§Ã£o

PASSOS PARA IMPLEMENTAR:

1. Copiar o cÃ³digo da VersÃ£o 1 acima
2. Substituir a seÃ§Ã£o de geraÃ§Ã£o no app.py (linhas ~210-320)
3. Modificar o mÃ³dulo llm_generator.py com o cÃ³digo do EXEMPLO_llm_generator_streaming.py
4. Testar com uma petiÃ§Ã£o real
5. Ajustar estilos e formataÃ§Ã£o conforme necessÃ¡rio

OPCIONAL - MELHORIAS FUTURAS:

- Adicionar botÃ£o "Pausar/Retomar" durante geraÃ§Ã£o
- Salvar chunks parciais em caso de erro
- Permitir editar texto em tempo real
- Adicionar modo "rÃ¡pido" vs "detalhado"
"""
